# DE 스터디 2주차 : 배경지식

## **허진호**

## 주제 : NoSQL, CAP theory and NoSQL use case

### NoSQL이란

> "Not Only SQL"
>
> 기존의 관계형 DBMS가 갖고있는 특성 뿐만 아니라 다른 특성들을 부가적으로 지원하다는 것을 의미.

<br></br>
### NoSQL의 특징

1. 데이터의 스키마를 미리 정의할 필요가 없으며, 시간이 지나더라도 언제든지 바꿀 수 있음

2. 여러 데이터베이스 서버를 묶어서(클러스터링) 하나의 데이터베이스를 구성할 수 있음

3. 데이터와 트래픽이 증가함에 따라 기존의 수직적 확장에서 장비의 수를 늘리는 수평적 확장 방식이 가능

   > 수직적 확장?
   >
   > 기존의 H/W를 성능이 더 좋은 H/W로 바꾸거나 CPU, RAM, DISK등을 증설하는 방법

4. Shard key를 기준으로 하나의 테이블을 수평 분할하여 서로 다른 클러스터에 분산 저장하고 질의 가능

   > Shard key란?
   >
   > 클러스트의 샤드들 간에 컬렉션의 도큐먼트를 어떻게 분산할 것인가를 결정하는 것
   >
   > 참조) http://cinema4dr12.tistory.com/508 

5. 테이블 간 연결해서 조회할 수 있는 조인 기능이 없음

6. 관계형 데이터베이스에서는 지원하는 데이터 처리 완결성(ACID)이 보장되지 않음

   > ACID이란?
   >
   > 데이터베이스 트랜잭션이 안전하게 수행된다는 것을 보장하기 위한 성질
   >
   > 1. 원자성 - 트랜잭션이과 관련된 작업이 부분적으로 실행되다가 중단되지 않는 것을 보장
   > 2. 일관성 - 트랜잭션이 실행을 성공적으로 완료하면 언제나 일관성 있는 데이터베이스 상태를 유지하는 것
   > 3. 고립성 - 트랜잭션을 수행 시 다른 트랜잭션의 연산 작업이 끼어들지 않도록 보장하는 것
   > 4. 지속성 - 성공적으로 수행된 트랜잭션은 영원히 반영되어야 함을 의미한다. 

<br></br>

### NoSQL의 데이터 모델 종류

**1) Key-Value Stores**

![](https://cdn-images-1.medium.com/max/600/1*swUK-eLWsk-wudXSXRgyYQ.png)

<br></br>

Key/Value Stores는 고유한 Key에 하나의 Value를 가지고 있는 형태를 의미한다. 이런 단순한 구조때문에 GET이나 PUT 함수만을 지원한다. 이 데이터 모델의 장점은 단순함이다. 매우 간단한 추상화를 통해 데이터를 쉽게 분할하고 쿼리할 수 있으므로 시스템은 짧은 대기시간과 높은 처리량을 달성할 수 있다. 하지만 복잡한 쿼리 작업이 필요한 경우에는 강력하지 않다. Key/Value Stores의 예로는 Redis가 있다.

<br></br>

**2) Wide Column Stores**

![](https://cdn-images-1.medium.com/max/800/0*Pi2jgiFuXOjQuC5_.png)

![](https://cdn-images-1.medium.com/max/800/0*VjyLe9cZfVYDd6mI.png)



Wide column stores는 Key-Value Store가 가지는 단점들을 보완한 형태이다. Key-Value는 value 필드를 필터링 할 수 없고 전체 값을 반환하거나 전체를 업데이트 해야하는 단점을 가지고 있다.  위 그림같이 Key-Value Store에 값 부분에 열을 추가함으로써 클라이언트가 요구하거나 업데이트 해야할 부분을 지정할 수 있다. Wide Column store는 단일 항목 수준에서 열이 지정되어 있기 때문에 전체 스키마가 존재하지 않기 때문에 관계형 데이터베이스와 같지 않다.

<br></br>

**3) Document  Stores**

: ![](https://cdn-images-1.medium.com/max/600/1*gdxUo2ojiTX2JQIkA2hxcQ.png)


Document Stores는 값을 JSON 문서와 같은 반 구조화된 형식으로 제한하는 Key-Value store이다. Key-Value Store과의 차이점은 값이 구조화되어 있기 때문에 데이터 값 내에서 쿼리를 실행할 수 있다는 것이다. Document Stores에서는 전체 데이터를 가져올 필요 없이 데이터 값이 나타내는 것을 이해하므로 필요한 데이터를 바로 검색할 수 있다. 전체 문서를 id로 쉽게 가져올 수 있다. 또한 문서 부분만을 검색하는 쿼리도 실행할 수 있다.  Mongo DB가 이 종류에 해당됩니다.

<br></br>

**4) Graph Stores**

: 그래프 DB는 SQL 또는 다른 모든 NoSQL 데이터베이스와 매우 다르게 데이터를 그래프로 구성한다. 페이스북 친구 데이터는 전형적인 예이다. 그래프 데이터베이스는 노드와 엣지로 구성되며 둘 다 중요한 정보를 포함할 수 있다. 예를 들어, 두 개의 다른 노드가 사람을 나타낼 수 있고 모든 노드 프로파일 세부 정보(이메일, 주소, 사진 등)가 해당 노드와 함께 저장된다. 그들 사이의 엣지는 두 사람이 친구라는 것을 나타낼 수 있고, 그들의 우정의 기간과 같은 데이터를 저장할 수 있다.

[출처1]: https://medium.baqend.com/nosql-databases-a-survey-and-decision-guidance-ea7823a822d
[출처2]: https://medium.com/@adamberlinskyschine/wtf-is-nosql-f1338cec6053
[출처3]: https://medium.com/indexoutofrange/what-is-the-problem-with-key-value-databases-and-how-wide-column-stores-solve-it-5445efbae538

<br></br>

### CAP 이론이란

분산된 시스템이 가지는 세가지 특성을 동시에 충족시키는 것은 불가능하며, 이 중 두 가지만을 취할 수 있다는 것

**1. Consistency (일관성)** - 모든 노드가 같은 시간에 같은 데이터를 보여줘야 한다.

**2. Availability (가용성)** - 특정 노드가 장애가 나도 서비스가 가능해야 한다.

> 또는 데이터 저장소에 대한 모든 동작(read, write 등)은 항상 성공적으로 리턴되어야 한다.
>
>   “서비스가 가능하다”와 “성공적으로 리턴”이라는 표현이 애매하다. 
>
> CAP를 설명하는 문서들 중 “Fail!!”이라고 리턴을 하는 경우도 “성공적인 리턴”이라고 설명하는 것을 보았다.
>
> 출처: <http://hamait.tistory.com/197> [HAMA 블로그]  

**3. Partitions Tolerance (분리 내구성)** - 일부 메시지를 손실하더라도 시스템은 정상 동작을 해야 한다.

[출처]: http://wiki.nex32.net/%EC%9A%A9%EC%96%B4/cap%EC%A0%95%EB%A6%AC

<br></br>

### CAP Theorem 오해와 진실

![](http://eincs.com/images/2013/06/truth-of-cap-theorem-diagram.png)



Partition Tolerance는 분할 내구성 보다는 분할 용인이라고 번역하는 것이 맞다. P의 정의는 네트워크가 임의의 메시지 손실을 할 수 있는 것을 허용하느냐이다. P를 포기하려면 절대로 장애가 나지 않는 네트워크를 구성해야 하지만 그런 것은 세상에 존재하지 않는다. 따라서 P는 언제나 선택되어야 하며 결국 Availability와 Consistency중 하나를 선택해야하는 것이다. 또한 CAP Theorem은 분산시스템이 전제조건이므로 RDBMS를 CAP에 적용하는 것은 맞지 않다. 그러므로 RDBMS를 CA라 하는 것은 맞지 않다.

[출처]: http://eincs.com/2013/07/misleading-and-truth-of-cap-theorem/

<br></br>

### PACELC Theorem

![](http://happinessoncode.com/images/cap-theorem-and-pacelc/pacelc.png)



CAP 이론의 이러한 단점들을 보완하기 위해 나온 이론이 바로 PACELC 이론이다. CAP 이론이 네트워크 파티션 상황에서 일관성-가용성 축을 이용하여 시스템의 특성을 설명한다면, PACELC 이론은 거기에 정상 상황이라는 새로운 축을 더한다. PACELC는 P(네트워크 파티션)상황에서 A(가용성)과 C(일관성)의 상충 관계와 E(else, 정상)상황에서 L(지연 시간)과 C(일관성)의 상충 관계를 설명한다.

<br></br>

### NoSQL use case?

**1) MongoDB**

MongoDB는 오픈소스 크로스 플랫폼에 도큐먼트 지향형 NoSQL 데이터베이스이다. 명확한 스키마 정의가 없는 경우 MongoDB를 선택하는 것이 좋고 실시간 분석을 위해 확장성과 캐슁이 필요한 경우 MongoDB를 선택하는 것이 좋다. 그러나 트랜잭션 데이터(계정 시스템 등)에는 적합하지 않다. MongoDB는 모바일 앱, 컨텐츠 관리, 실시간 분석, IoT 애플리케이션 등에 자주 사용된다.

 

**2) DynamoDB**

DynamoDB는 AWS 스택을 이미 사용하고 있고 NoSQL 데이터베이스가 필요한 경우 가장 먼저 적용을 고려해보아야 할 데이터베이스이다. 



**3) Redis**

Redis는 인메모리에서 돌아가는 NoSQL 데이터베이스이다. 인메모리DB라  빠른 속도가 강점이다. 카카오뿐아니라 트위터, 페이스북, 인스타그램, 네이버 등 유명 인터넷 업체들이 사용자들의 대규모 메시지를 실시간으로 처리하기 위해 Redis를 사용 중이다.  Redis의 특징 중 하나는 '싱글 쓰레드'라는 점이다. 싱글 쓰레드는 1번에 1개의 명령어만 실행할 수 있다. 한 서비스에서 요청된 명령어에 대한 작업이 끝나기 전까진 다른 서비스에서 요청하는 명령을 못 받아들인다. 모든 키를 보여주거나 플러싱하는 명령어는 테스트 환경이나 소량의 데이터를 관리하는 시스템에서 모니터링하는 용도로만 써야 한다. 실행 대상을 전수처리하기 때문에 점차 데이터를 쌓아가는 환경에서는 운영에 차질을 빚을 정도로 속도가 느려진다. 일반적으로 텍스트 위주의 데이터를 처리하는데 적합하다.

[출처]: http://www.zdnet.co.kr/news/news_view.asp?artice_id=20131119174125



**4) ElasticSearch**

루씬을 기반으로 한 텍스트 검색 엔진 라이브러리이다.  사전 매핑 없이 JSON 문서 형식으로 입력하면 별도의 이벤트가 없어도 바로 색인을 시작한다. 이렇게 저장된 데이터는 별도의 재시작/갱신 없이도 바로 검색에 사용될 수 있다. 이는 곧 색인 작업이 완료됨과 동시에 검색이 가능하다는걸 의미한다. 이러한 특징들 덕분에 SOLR(솔라) 와 비교하여 실시간 검색 엔진 구현에 좀 더 적합하다.

[출처]: http://louie0.tistory.com/131

------

## 정지윤

### 주제: Spark와 Kafka, 어디서 쓰이는지 / use case


spark(Apache Spark)란, 대규모 데이터 처리를 위한 통합 분석 엔진이다.

<Spark 특징>

1. 속도 : Apache Spark는 최첨단 DAG 스케줄러, 쿼리 최적화 프로그램 및 실제 실행 엔진을 사용하여 배치 및 스트리밍 데이터 모두에 대해 높은 성능을 제공합니다.

2. 사용의 용이성 : Spark은 병렬 응용 프로그램을 쉽게 만들 수 있는 80개 이상의 고급 연산자를 제공합니다. 또한 Scala, Python, R 및 SQL 쉘에서 대화식으로 사용할 수 있습니다.

3. 대부분 : Spark은 SQL 및 Data Frames, 기계 학습을 위한 MLlib, Graph X 및 Spark Streaming과 같은 라이브러리 스택을 제공합니다. 동일한 응용 프로그램에서 이 라이브러리를 완벽하게 결합할 수 있습니다.

4. 어디서나 실행 가능 : Spark는 Hadoop, Apache Mesos, Kubernetes, 독립형 또는 클라우드에서 실행됩니다. 다양한 데이터 소스에 액세스할 수 있습니다.

Apache Spark 의 주요 사용 사례

1. 스트리밍 데이터 - 많은 양의 데이터가 매일 처리되기 때문에 회사는 실시간으로 모든 데이터를 스트리밍하고 분석할 수 있어야 합니다. Spark Streaming에는 이러한 추가 작업 부하를 처리할 수 있는 기능이 있습니다. 

+ 스트리밍 ETL - 데이터웨어 하우스 환경에서 배치 처리에 사용되는 전통적인 ETL (추출, 변환,로드) 도구는 데이터를 읽고 데이터베이스 호환 형식으로 변환 한 다음 대상 데이터베이스에 기록해야 합니다. Streaming ETL을 사용하면 데이터를 데이터 저장소에 푸시하기 전에 데이터를 지속적으로 정리하고 집계할 수 있습니다.

+ 데이터 풍부화 - Spark Streaming 기능은 정적 데이터와 결합하여 실제 데이터를 풍부하게 하므로 조직에서보다 완벽한 실시간 데이터 분석을 수행할 수 있습니다. 온라인 광고주는 과거의 고객 데이터와 실시간 고객 행동 데이터를 결합하고 고객이 수행하는 작업과 관련하여보다 개인화되고 타겟이 명확한 광고를 실시간으로 제공하기 위해 데이터 보강을 사용합니다.

+ 트리거(trigger) 이벤트 감지 - Spark Streaming을 사용하면 시스템에서 잠재적으로 심각한 문제를 나타낼 수 있는 드문 비정상적인 동작을 신속하게 감지하고 대응할 수 있습니다. 금융 기관은 트리거를 사용하여 사기 거래를 탐지하고 사기를 막습니다. 병원은 또한 환자의 생체 신호를 모니터링하면서 잠재적인 위험한 건강 변화를 탐지하기 위해 트리거를 사용합니다. 즉각적인 적절한 조치를 취할 수 있는 적절한 간병인에게 자동 경고를 보냅니다.

+ 복잡한 세션 분석 - Spark Streaming을 사용하여 웹 사이트 또는 응용 프로그램에 로그인 한 후 사용자 활동과 같은 라이브 세션과 관련된 이벤트를 그룹화하고 신속하게 분석 할 수 있습니다. 세션 정보는 또한 기계 학습 모델을 지속적으로 업데이트하는 데 사용될 수 있습니다. Netflix와 같은 회사는 이 기능을 사용하여 사용자가 사이트에 참여하는 방식에 대한 즉각적인 통찰력을 얻고 더 많은 실시간 영화 추천을 제공합니다.


2. 기계 학습
Apache Spark의 많은 사용 사례 중 하나는 기계 학습 기능입니다. Spark은 고급 분석을 수행하기 위한 통합 프레임 워크와 함께 제공됩니다. 이 프레임 워크는 사용자가 데이터 집합에 대해 반복적인 쿼리를 실행하는 것을 돕습니다. 이 프레임 워크에서 발견되는 구성 요소 중에는 Spark의 확장 가능한 Machine Learning Library (MLlib)가 있습니다. MLlib는 클러스터링, 분류 및 차원 감소와 같은 영역에서 작동할 수 있습니다. 이 모든 기능을 통해 Spark은 예측 정보, 마케팅 목적의 고객 세분화 및 정서 분석과 같은 매우 일반적인 대형 데이터 기능에 사용할 수 있습니다. 추천 엔진을 사용하는 회사는 Spark이 작업을 빨리 완료하게 만듭니다.

+ 네트워크 보안 : Spark의 기계 학습 기능을 위한 훌륭한 비즈니스 사례이다. Spark 스택의 다양한 구성 요소를 활용하여 보안 공급자는 악의적인 활동의 흔적을 실시간으로 데이터 패킷 검사를 수행할 수 있습니다. 프런트 엔드에서 Spark Streaming을 사용하면 보안 분석가가 패킷을 저장소 플랫폼으로 전달하기 전에 알려진 위협을 검사 할 수 있습니다. 스토리지에 도착하면 패킷은 MLlib와 같은 다른 스택 구성 요소를 통해 추가 분석을 받습니다. 따라서 보안 공급자는 진화하면서 새로운 위협에 대해 알아낼 수 있습니다. 해커보다 앞서 클라이언트를 보호하고 실시간으로 보호합니다.

     
3. 대화식 분석
스파크의 가장 주목할만한 특징은 대화식 분석 기능입니다. MapReduce는 일괄 처리를 처리하도록 설계되었으며 Hive 또는 Pig와 같은 SQL-on-Hadoop 엔진은 대화형 분석을 하기에는 너무 느립니다. 그러나 Apache Spark는 샘플링 없이 탐색 쿼리를 수행할 수 있을 정도로 빠릅니다. Spark은 SQL, R 및 Python을 비롯한 여러 개발 언어와도 인터페이스합니다. Spark와 시각화 도구를 결합하여 복잡한 데이터 세트를 처리하고 대화식으로 시각화할 수 있습니다.

     
4. 안개 계산
거대한 데이터 분석이 많은 관심을 끌고 있는 반면, 기술 공동체의 상상력을 자극하는 개념은 IoT입니다. IoT는 서로 간에 그리고 사용자와 통신하는 작은 센서를 가진 물체와 장치를 내장하여 완전히 상호 연결된 세계를 만듭니다. 이 세상은 엄청난 양의 데이터를 수집하고 처리하며 사람들이 일상 생활에서 사용할 수있는 혁신적인 새로운 기능과 응용 프로그램을 제공합니다. 그러나 IoT가 확장됨에 따라 거대한 양의 기계 및 센서 데이터를 대량으로 병렬 처리할 필요가 있습니다. 그러나 이러한 모든 처리는 클라우드의 현재 분석 기능으로 관리하기가 어렵습니다.

    

+스파크를 사용하지 않을 때

다목적이지만, 그렇다고 아파치 스파크의 메모리 내 기능이 모든 유스 케이스에 가장 적합하다는 것을 의미하지는 않습니다. 더 구체적으로 Spark는 다중 사용자 환경 으로 설계되지 않았습니다. 스파크 사용자는 액세스 권한이있는 메모리가 데이터 집합에 충분한 지 여부를 알아야합니다. 더 많은 사용자를 추가하는 것은 사용자가 동시에 프로젝트를 실행하기 위해 메모리 사용을 조정해야하므로 더 복잡해집니다. 이러한 유형의 동시성을 처리 할 수 없기 때문에 대규모 일괄 처리 프로젝트의 경우 Apache Hive와 같은 대체 엔진을 고려해야합니다.

     
     
     
Apache Kafka® : 분산형 스트리밍 플랫폼

<세 가지 주요 기능>

1. 메시지 큐 또는 엔터프라이즈 메시징 시스템과 유사하게 레코드 스트림을 게시하고 구독

2. 내결함성이 강한 방식으로 레코드 스트림을 저장

3.레코드 스트림을 처리



두 가지 광범위한 종류의 응용 프로그램에 사용

- 시스템 또는 응용 프로그램 간에 데이터를 안정적으로 얻는 실시간 스트리밍 데이터 파이프 라인 구축

- 데이터 스트림을 변환하거나 이에 반응하는 실시간 스트리밍 애플리케이션 구축

     


<4가지 핵심 API>

생산자 API : 하나 개 이상의 카프카 주제에 레코드의 스트림을 게시 할 수있는 응용 프로그램을 할 수 있습니다.

소비자 API : 응용 프로그램이 하나 개 이상의 주제에 가입 그들에게 생산 기록의 스트림을 처리 할 수 있습니다.

스트림 API : 애플리케이션이 역할을 할 수 있도록 스트림 프로세서 유효 입력이 출력 스트림에 스트림 변환, 하나 개 이상의 항목에서 입력 스트림을 소비하는 하나 개 이상의 출력 항목을 출력 스트림을 생성한다.

커넥터 API : 구축하고 기존의 응용 프로그램이나 데이터 시스템에 카프카의 주제를 연결 재사용 생산자 또는 소비자를 실행 할 수 있습니다. 예를 들어, 관계형 데이터베이스에 대한 커넥터는 테이블에 대한 모든 변경 사항을 캡처 할 수 있습니다.

     
<아파치 카프카 (Apache Kafka®)의 인기있는 사용 사례>
     
1. 메시지

Kafka는보다 전통적인 메시지 브로커를 대신하여 잘 작동합니다. 메시지 브로커는 다양한 이유로 사용됩니다 (데이터 생성자에서 처리를 분리하여 처리되지 않은 메시지를 버퍼링하는 등). 대부분의 메시징 시스템과 비교하여 Kafka는 뛰어난 처리량, 기본 제공 파티셔닝, 복제 및 내결함성을 갖추고있어 대규모 메시지 처리 응용 프로그램에 적합한 솔루션입니다.


2. 웹 사이트 활동 추적

Kafka의 원래의 사용 사례는 사용자 활동 추적 파이프 라인을 실시간 게시 - 구독 피드 집합으로 재구성 할 수 있어야했습니다. 이는 사이트 활동 (페이지 뷰, 검색 또는 사용자가 취할 수있는 기타 작업)이 활동 유형별로 하나의 주제와 함께 중앙 주제에 게시됨을 의미합니다. 이 피드는 실시간 처리, 실시간 모니터링, 오프라인 처리 및보고를 위해 Hadoop 또는 오프라인 데이터웨어 하우징 시스템에로드하는 것을 포함하여 다양한 사용 사례에 대한 구독에 사용할 수 있습니다.


3. 측정 항목

Kafka는 종종 운영 모니터링 데이터로 사용됩니다. 여기에는 분산 응용 프로그램의 통계를 집계하여 운영 데이터의 중앙 집중식 피드를 생성하는 작업이 포함됩니다.


4. 로그 집계
 

로그 집계는 일반적으로 물리적 인 로그 파일을 서버에서 수집하여 중앙 서버 (파일 서버 또는 아마도 HDFS)에 저장하여 처리합니다. Kafka는 파일의 세부 사항을 추상화하여 로그 또는 이벤트 데이터를 메시지 스트림으로보다 깔끔하게 추상화합니다. 이를 통해 대기 시간이 더 낮은 처리가 가능하며 여러 데이터 소스 및 분산 된 데이터 소비를보다 쉽게 지원할 수 있습니다. Scribe 또는 Flume과 같은 로그 중심 시스템과 비교하여 카프카는 성능이 우수하고 복제로 인해 내구성이 강화되었으며 엔드 투 엔드 대기 시간이 훨씬 낮습니다.


5. 스트림 처리

Kafka의 많은 사용자는 여러 단계로 구성된 처리 파이프 라인에서 데이터를 처리합니다.이 단계에서는 원시 입력 데이터가 카프카 항목에서 소비 된 다음 추가 소비 또는 후속 처리를 위해 새로운 주제로 집계, 강화 또는 변환됩니다. 예를 들어 뉴스 기사를 추천하기위한 처리 파이프 라인은 RSS 피드의 기사 콘텐츠를 크롤링하여 "기사"주제에 게시 할 수 있습니다. 추가 처리는이 컨텐츠를 정규화 또는 중복 제거하고 정리 된 기사 컨텐츠를 새 주제에 게시 할 수 있습니다. 최종 처리 단계에서이 내용을 사용자에게 권장하려고 시도 할 수 있습니다. 이러한 프로세싱 파이프 라인은 개별 주제를 기반으로 실시간 데이터 흐름의 그래프를 생성합니다. 0.10.0.0부터는 가볍지 만 강력한 스트림 처리 라이브러리 인 Kafka Streams 위에서 설명한대로 이러한 데이터 처리를 수행하기 위해 Apache Kafka에서 사용할 수 있습니다. Kafka Streams 외에도 다른 오픈 소스 스트림 처리 도구에는 Apache Storm 과 Apache Samza가 있습니다.


6. 이벤트 소싱

이벤트 소싱 은 상태 변경이 시간 순서로 기록 된 레코드 순서로 기록되는 응용 프로그램 디자인 스타일입니다. 매우 큰 저장된 로그 데이터에 대한 Kafka의 지원은이 스타일로 구축 된 응용 프로그램을 위한 훌륭한 백엔드입니다.


7. 커밋 로그

Kafka는 분산 시스템에 대한 일종의 외부 커밋 로그 역할을 할 수 있습니다. 이 로그는 노드 간에 데이터를 복제하는 데 도움을 주며 장애가 발생한 노드가 데이터를 복원할 수 있는 재동기화 메커니즘의 역할을 합니다. Kafka의 로그 압축 기능은 이 사용법을 지원합니다. 이 사용법에서 Kafka는 Apache BookKeeper 프로젝트와 유사합니다.

     

     
<빅데이터의 윤활유로 쓰이는 스파크와 카프카>

빅데이터의 가장 큰 도전과제로 종종 '분석'이 지목되지만 그 단계로 들어가기 전에 먼저 기업 데이터를 소화하고 사용할 수 있어야 한다. 그 지점에서 필요한 것이 바로 '아파치 카프카'다.

링크드인이 개발한 카프카는 웹사이트, 애플리케이션, 센서 등에서 취합한 데이터 스트림을 실시간으로 관리하기 위한 오픈 소스 시스템이다.

본질적으로 카프카는 기업의 사용자 활동, 로그, 애플리케이션 측정치, 스톡 티커, 기기 계측장치 등에 대한 대용량 데이터를 수집하고 이를 기업 사용자들이 실시간 스트림으로 소비할 수 있게 만들어주는 일종의 '중추 신경'으로 작동한다.


------

## 안효진

### 주제:

------

## 장혜정

### 주제: Hadoop, HDFS + MapReduce // use case

### Hadoop이란?
>대용량 데이터를 분산 처리할 수 있는 오픈소스 자바 프레임워크
> 분산 저장(HDFS)와 병렬처리(Map&Reduce), 이렇게 2개의 프레임워크로 구성되어 있다. 
------

